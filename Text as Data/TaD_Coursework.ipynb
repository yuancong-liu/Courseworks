{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TaD Coursework Skeleton 2021 - May-June",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gv2i9fNDvrg"
      },
      "source": [
        "## Post Sentiment Classification Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG9BpbQt3-ko"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_data = pd.read_json(\"https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_train.json\")\n",
        "\n",
        "validation_data = pd.read_json(\"https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_validation.json\")\n",
        "\n",
        "test_data = pd.read_json(\"https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_test.json\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTTDVPS-gYFn"
      },
      "source": [
        "import spacy\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfXc0F4K1ppE"
      },
      "source": [
        "# Q1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "eZdMGUlu1Xvc",
        "outputId": "dbdcd513-19ac-4b9e-e11f-254d1c1889d9"
      },
      "source": [
        "#check the training data\n",
        "train_data.head(5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "      <th>majority_type</th>\n",
              "      <th>is_first_post</th>\n",
              "      <th>post_depth</th>\n",
              "      <th>in_reply_to</th>\n",
              "      <th>sentiment.polarity</th>\n",
              "      <th>sentiment.subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7f317</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>Melodrama_</td>\n",
              "      <td>It's a sad realization, isn't it?</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>t1_cy7erc5</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7hlyf</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>Melodrama_</td>\n",
              "      <td>I told her a couple of minutes ago that I didn...</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>t1_cy7erc5</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.483631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7etrr</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>TreatYoSelves</td>\n",
              "      <td>Leeches don't make good friends.</td>\n",
              "      <td>answer</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>t3_3xshx9</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7hhpq</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>Melodrama_</td>\n",
              "      <td>I just ended it. Apparently she wasn't a good ...</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>t1_cy7etrr</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7q0qg</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>TreatYoSelves</td>\n",
              "      <td>Good for you!  Make sure you stick with it.</td>\n",
              "      <td>appreciation</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>t1_cy7hhpq</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.744444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       subreddit  ... sentiment.subjectivity\n",
              "0  relationships  ...               1.000000\n",
              "1  relationships  ...               0.483631\n",
              "2  relationships  ...               0.600000\n",
              "3  relationships  ...               0.475000\n",
              "4  relationships  ...               0.744444\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "3mJbcvE40wAo",
        "outputId": "8baddfaa-a54d-4b11-90e5-f5384c8e3837"
      },
      "source": [
        "polarity_counts = train_data['sentiment.polarity'].value_counts()\n",
        "print(polarity_counts)\n",
        "polarity_counts.plot.bar()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral          7679\n",
            "positive         3231\n",
            "negative          878\n",
            "very positive     253\n",
            "very negative      97\n",
            "Name: sentiment.polarity, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fc787b3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "axNHK0zT1SDr",
        "outputId": "50fbbc3e-8262-45ee-b148-6d35efc82919"
      },
      "source": [
        "polarity_counts = validation_data['sentiment.polarity'].value_counts()\n",
        "print(polarity_counts)\n",
        "polarity_counts.plot.bar()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral          1961\n",
            "positive          845\n",
            "negative          215\n",
            "very positive      73\n",
            "very negative      15\n",
            "Name: sentiment.polarity, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fc78bbe50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "ycX_y7jp1Z3R",
        "outputId": "024a471b-bbfa-4ff6-d9d5-df2ca3e663b3"
      },
      "source": [
        "polarity_counts = test_data['sentiment.polarity'].value_counts()\n",
        "print(polarity_counts)\n",
        "polarity_counts.plot.bar()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral          2514\n",
            "positive         1102\n",
            "negative          282\n",
            "very positive      86\n",
            "very negative      32\n",
            "Name: sentiment.polarity, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fc7992110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoYJcuQx118p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9ff95f-7b05-45fe-9eeb-e6a0e716ac2b"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.remove_pipe('tagger')\n",
        "nlp.remove_pipe('parser')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fb57215e3d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubzN-rYsPSPH",
        "outputId": "75d47e8a-f1d0-4979-9442-c38e1c0ecdc6"
      },
      "source": [
        "#download a stopword list\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUMNST_KPKgp"
      },
      "source": [
        "#tokenize\n",
        "def spacy_tokenize(string):\n",
        "  tokens = list()\n",
        "  doc = nlp(string)\n",
        "  for token in doc:\n",
        "    tokens.append(token)\n",
        "  return tokens\n",
        "\n",
        "#normalize\n",
        "def normalize(tokens):\n",
        "  normalized_tokens = list()\n",
        "  for token in tokens:\n",
        "    normalized = token.text.lower().strip()\n",
        "    if ((token.is_alpha or token.is_digit)):\n",
        "      normalized_tokens.append(normalized)\n",
        "  return normalized_tokens\n",
        "  return normalized_tokens\n",
        "\n",
        "#tokenize and normalize\n",
        "def tokenize_normalize(string):\n",
        "  return normalize(spacy_tokenize(string))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOYI0C6RQslJ"
      },
      "source": [
        "# use smaller datasets\n",
        "# train_data = train_data[0:500]\n",
        "# validation_data = validation_data[0:500]\n",
        "# test_data = test_data[0:500]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfLOWFLEPyOW"
      },
      "source": [
        "# Pass in the tokenizer as the tokenizer to the vectorizer.\n",
        "# Create a one-hot encoding vectorizer.\n",
        "one_hot_vectorizer = CountVectorizer(tokenizer=tokenize_normalize, binary=True)\n",
        "train_features = one_hot_vectorizer.fit_transform(train_data['body'])\n",
        "\n",
        "# This creates input features for our classification on all subsets of our collection.\n",
        "validation_features = one_hot_vectorizer.transform(validation_data['body'])\n",
        "test_features = one_hot_vectorizer.transform(test_data['body'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geMP8Lt5Rr9C"
      },
      "source": [
        "train_labels = train_data['sentiment.polarity']\n",
        "validation_labels = validation_data['sentiment.polarity']\n",
        "test_labels = test_data['sentiment.polarity']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mORUGTBUSp4"
      },
      "source": [
        "def evaluation_summary(description, predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='weighted')\n",
        "  recall = recall_score(predictions, true_labels, average='weighted')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1_weighted = fbeta_score(predictions, true_labels, 1, average='weighted') #1 means f_1 measure\n",
        "  f1_macro = fbeta_score(predictions, true_labels, 1, average='macro')\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1_w=%0.3f F1_m=%0.3f\" % (description,accuracy,precision,recall,f1_weighted,f1_macro))\n",
        "  print(classification_report(predictions, true_labels, digits=3, zero_division = 0))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions)) # Note the order here is true, predicted\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6lBhFybUDQl"
      },
      "source": [
        "## Dummy Classifier\n",
        "1. `Dummy Classifier` with `strategy=\"most_frequent\"`\n",
        "\n",
        "2. `Dummy Classifier` with `strategy=\"stratified\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyKvRX2dRzbW",
        "outputId": "2096c220-d4c6-42fe-bca2-ae5e2e2da56a"
      },
      "source": [
        "dummy_mf = DummyClassifier(strategy='most_frequent')\n",
        "dummy_mf.fit(train_features, train_labels)\n",
        "print(dummy_mf.score(test_features, test_labels))\n",
        "evaluation_summary(\"Dummy Majority\", dummy_mf.predict(test_features), test_labels)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.625996015936255\n",
            "Evaluation for: Dummy Majority\n",
            "Classifier 'Dummy Majority' has Acc=0.626 P=1.000 R=0.626 F1_w=0.770 F1_m=0.154\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.000     0.000     0.000         0\n",
            "      neutral      1.000     0.626     0.770      4016\n",
            "     positive      0.000     0.000     0.000         0\n",
            "very negative      0.000     0.000     0.000         0\n",
            "very positive      0.000     0.000     0.000         0\n",
            "\n",
            "     accuracy                          0.626      4016\n",
            "    macro avg      0.200     0.125     0.154      4016\n",
            " weighted avg      1.000     0.626     0.770      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0  282    0    0    0]\n",
            " [   0 2514    0    0    0]\n",
            " [   0 1102    0    0    0]\n",
            " [   0   32    0    0    0]\n",
            " [   0   86    0    0    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cCsUerTdVbq",
        "outputId": "1166d6c1-2253-4156-e4d8-9ca1dba3011e"
      },
      "source": [
        "dummy_prior = DummyClassifier(strategy='stratified')\n",
        "dummy_prior.fit(train_features, train_labels)\n",
        "print(dummy_prior.score(test_features, test_labels))\n",
        "evaluation_summary(\"Dummy Prior\", dummy_prior.predict(test_features), test_labels)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4676294820717131\n",
            "Evaluation for: Dummy Prior\n",
            "Classifier 'Dummy Prior' has Acc=0.462 P=0.463 R=0.462 F1_w=0.462 F1_m=0.190\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.060     0.057     0.059       296\n",
            "      neutral      0.619     0.614     0.616      2535\n",
            "     positive      0.256     0.268     0.262      1054\n",
            "very negative      0.000     0.000     0.000        36\n",
            "very positive      0.012     0.011     0.011        95\n",
            "\n",
            "     accuracy                          0.462      4016\n",
            "    macro avg      0.189     0.190     0.190      4016\n",
            " weighted avg      0.463     0.462     0.462      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  17  192   64    4    5]\n",
            " [ 194 1556  678   21   65]\n",
            " [  73  714  282    9   24]\n",
            " [   3   21    8    0    0]\n",
            " [   9   52   22    2    1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLrX9sUdaXdd"
      },
      "source": [
        "## Logistic Regression\n",
        "3. `LogisticRegression` with `One-hot vectorization`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvn9SKeiUImk",
        "outputId": "fe1cc0df-a725-4ac8-9aa4-141ebf1f79e6"
      },
      "source": [
        "lr = LogisticRegression(solver='saga', max_iter = 1000)\n",
        "lr_model = lr.fit(train_features, train_labels)\n",
        "evaluation_summary(\"LR onehot\", lr_model.predict(test_features), test_labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR onehot\n",
            "Classifier 'LR onehot' has Acc=0.748 P=0.787 R=0.748 F1_w=0.763 F1_m=0.476\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.245     0.479     0.324       144\n",
            "      neutral      0.877     0.778     0.825      2835\n",
            "     positive      0.635     0.714     0.672       980\n",
            "very negative      0.125     0.667     0.211         6\n",
            "very positive      0.279     0.471     0.350        51\n",
            "\n",
            "     accuracy                          0.748      4016\n",
            "    macro avg      0.432     0.622     0.476      4016\n",
            " weighted avg      0.787     0.748     0.763      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  69  204    8    1    0]\n",
            " [  67 2206  227    1   13]\n",
            " [   3  385  700    0   14]\n",
            " [   5   23    0    4    0]\n",
            " [   0   17   45    0   24]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yRKibaoelb7"
      },
      "source": [
        "4. `LogisticRegression` with `TF-IDF vectorization` **(default settings)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5BzF0bQbvOF"
      },
      "source": [
        "ngram_vectorizer = TfidfVectorizer(tokenizer=tokenize_normalize)\n",
        "train_features_idf = ngram_vectorizer.fit_transform(train_data['body'])\n",
        "\n",
        "validation_features_idf = ngram_vectorizer.transform(validation_data['body'])\n",
        "test_features_idf = ngram_vectorizer.transform(test_data['body'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttrhjtkRezXK",
        "outputId": "e16bb57c-1b2d-4ad9-8317-207cbc515e58"
      },
      "source": [
        "lr_idf = LogisticRegression(solver='saga', max_iter = 1000)\n",
        "lr_idf_model = lr_idf.fit(train_features_idf, train_labels)\n",
        "evaluation_summary(\"LR tf-idf\", lr_idf_model.predict(test_features_idf), test_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR tf-idf\n",
            "Classifier 'LR tf-idf' has Acc=0.741 P=0.853 R=0.741 F1_w=0.780 F1_m=0.356\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.089     0.625     0.155        40\n",
            "      neutral      0.944     0.738     0.829      3212\n",
            "     positive      0.517     0.758     0.615       752\n",
            "very negative      0.000     0.000     0.000         0\n",
            "very positive      0.105     0.750     0.184        12\n",
            "\n",
            "     accuracy                          0.741      4016\n",
            "    macro avg      0.331     0.574     0.356      4016\n",
            " weighted avg      0.853     0.741     0.780      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  25  249    8    0    0]\n",
            " [  11 2372  130    0    1]\n",
            " [   0  530  570    0    2]\n",
            " [   4   28    0    0    0]\n",
            " [   0   33   44    0    9]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7s58NE8hJws"
      },
      "source": [
        "5. `SVC Classifier` with `One-hot vectorization` **(SVM with RBF kernel, default settings))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq-FWzyAfxgi",
        "outputId": "d57d1640-00c1-4385-cbe8-0f6f48a743f7"
      },
      "source": [
        "svc = SVC(kernel='rbf')\n",
        "svc.fit(train_features, train_labels)\n",
        "evaluation_summary(\"SVC\", svc.predict(test_features), test_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: SVC\n",
            "Classifier 'SVC' has Acc=0.730 P=0.875 R=0.730 F1_w=0.782 F1_m=0.287\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.014     0.800     0.028         5\n",
            "      neutral      0.958     0.721     0.823      3339\n",
            "     positive      0.470     0.771     0.584       672\n",
            "very negative      0.000     0.000     0.000         0\n",
            "very positive      0.000     0.000     0.000         0\n",
            "\n",
            "     accuracy                          0.730      4016\n",
            "    macro avg      0.288     0.458     0.287      4016\n",
            " weighted avg      0.875     0.730     0.782      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   4  270    8    0    0]\n",
            " [   0 2409  105    0    0]\n",
            " [   0  584  518    0    0]\n",
            " [   1   31    0    0    0]\n",
            " [   0   45   41    0    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgCt7GxEhGCL",
        "outputId": "30bc3739-6735-454d-c50d-ef87ebc62390"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "knn_model = knn.fit(train_features_idf, train_labels)\n",
        "evaluation_summary(\"KNN\", knn_model.predict(test_features_idf), test_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: KNN\n",
            "Classifier 'KNN' has Acc=0.634 P=0.991 R=0.634 F1_w=0.768 F1_m=0.171\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.004     1.000     0.007         1\n",
            "      neutral      1.000     0.631     0.774      3981\n",
            "     positive      0.027     0.909     0.053        33\n",
            "very negative      0.000     0.000     0.000         0\n",
            "very positive      0.012     1.000     0.023         1\n",
            "\n",
            "     accuracy                          0.634      4016\n",
            "    macro avg      0.208     0.708     0.171      4016\n",
            " weighted avg      0.991     0.634     0.768      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   1  281    0    0    0]\n",
            " [   0 2513    1    0    0]\n",
            " [   0 1072   30    0    0]\n",
            " [   0   32    0    0    0]\n",
            " [   0   83    2    0    1]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1THh_6dhjw_q"
      },
      "source": [
        "From the results above, we can see the classifier `LogisticRegression` with `One-hot vectorization` has the highest macro F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xjbWWtwOGrL8",
        "outputId": "9ac0a956-96a9-4f2d-812e-3b576d7112ab"
      },
      "source": [
        "f1score = np.array([0.211, 0.324, 0.825, 0.672, 0.350])\n",
        "labels= [\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"]\n",
        "\n",
        "plt.bar(labels, f1score)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNEiLYjglbpd"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4-AKvkimjD2"
      },
      "source": [
        "class ItemSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"For data grouped by feature, select subset of data at a provided key.    \"\"\"\n",
        "\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, x, y = None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_dict):\n",
        "        return data_dict[self.key]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn6pZnr0kWfK"
      },
      "source": [
        "prediction_pipeline = Pipeline([\n",
        "              ('selector', ItemSelector(key='body')),\n",
        "              ('tf-idf', TfidfVectorizer()),\n",
        "              ('logreg', LogisticRegression(solver='saga', max_iter = 1000))\n",
        "              ])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac3cydN-ntSs",
        "outputId": "fc0179a3-539f-4839-d8bc-6bd7c9809090"
      },
      "source": [
        "params = {\n",
        "    'logreg__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000],\n",
        "    'tf-idf__sublinear_tf': [True, False],\n",
        "    'tf-idf__max_features': range(0, 50000, 1000),\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(prediction_pipeline, param_grid=params, n_jobs=1, verbose=1, scoring='f1_macro', cv=2)\n",
        "grid_search.fit(train_data, train_labels)\n",
        "best_parameters = grid_search.best_estimator_.get_params()\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 900 candidates, totalling 1800 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed: 112.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tlogreg__C: 100\n",
            "\ttf-idf__max_features: 3000\n",
            "\ttf-idf__sublinear_tf: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjkEhrWEOdlG",
        "outputId": "b81f5712-6a56-48f8-93d7-f7d62529c4da"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params_2 = {\n",
        "    'tf-idf__max_df': [1000, 1200, 1400, 1600, 1800]\n",
        "}\n",
        "\n",
        "grid_search_2 = GridSearchCV(prediction_pipeline, param_grid=params_2, n_jobs=1, verbose=1, scoring='f1_macro', cv=2)\n",
        "grid_search_2.fit(train_data, train_labels)\n",
        "best_parameters = grid_search_2.best_estimator_.get_params()\n",
        "for param_name in sorted(params_2.keys()):\n",
        "  print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\ttf-idf__max_df: 1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMMQuMfWN_Zy",
        "outputId": "e5841e5e-d37a-4827-a8bd-8462edb18909"
      },
      "source": [
        "prediction_pipeline_tuned = Pipeline([\n",
        "              ('selector', ItemSelector(key='body')),\n",
        "              ('tf-idf', TfidfVectorizer(sublinear_tf=False, max_features=3000)),\n",
        "              ('logreg', LogisticRegression(solver='saga', max_iter = 1000, C=100))\n",
        "              ])\n",
        "prediction_pipeline_tuned.fit(train_data, train_labels)\n",
        "evaluation_summary(\"LR tf-idf\", prediction_pipeline_tuned.predict(test_data), test_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR tf-idf\n",
            "Classifier 'LR tf-idf' has Acc=0.747 P=0.756 R=0.747 F1_w=0.751 F1_m=0.512\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.355     0.427     0.388       234\n",
            "      neutral      0.834     0.804     0.819      2607\n",
            "     positive      0.694     0.713     0.703      1073\n",
            "very negative      0.250     0.320     0.281        25\n",
            "very positive      0.349     0.390     0.368        77\n",
            "\n",
            "     accuracy                          0.747      4016\n",
            "    macro avg      0.496     0.531     0.512      4016\n",
            " weighted avg      0.756     0.747     0.751      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 100  167    9    5    1]\n",
            " [ 119 2096  264   12   23]\n",
            " [   5  309  765    0   23]\n",
            " [   9   15    0    8    0]\n",
            " [   1   20   35    0   30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1st927azun2a",
        "outputId": "2b551096-10ce-40be-f996-5b313c18aeaf"
      },
      "source": [
        " prediction_pipeline_tuned = Pipeline([\n",
        "              ('selector', ItemSelector(key='body')),\n",
        "              ('tf-idf', TfidfVectorizer(sublinear_tf=False, max_features=3000, max_df=1200)),\n",
        "              ('logreg', LogisticRegression(solver='saga', max_iter = 1000, C=100))\n",
        "              ])\n",
        "prediction_pipeline_tuned.fit(train_data, train_labels)\n",
        "evaluation_summary(\"LR tf-idf\", prediction_pipeline_tuned.predict(test_data), test_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR tf-idf\n",
            "Classifier 'LR tf-idf' has Acc=0.750 P=0.758 R=0.750 F1_w=0.753 F1_m=0.541\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.404     0.485     0.441       235\n",
            "      neutral      0.836     0.805     0.820      2610\n",
            "     positive      0.685     0.702     0.693      1076\n",
            "very negative      0.344     0.458     0.393        24\n",
            "very positive      0.326     0.394     0.357        71\n",
            "\n",
            "     accuracy                          0.750      4016\n",
            "    macro avg      0.519     0.569     0.541      4016\n",
            " weighted avg      0.758     0.750     0.753      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 114  154    8    4    2]\n",
            " [ 109 2102  273    9   21]\n",
            " [   6  321  755    0   20]\n",
            " [   5   14    2   11    0]\n",
            " [   1   19   38    0   28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je0CvGk2c-Nm",
        "outputId": "6e798532-d058-4281-f708-d0cd5fbfdde7"
      },
      "source": [
        "# print 20 pieces of mispredicted data\n",
        "predicted = prediction_pipeline_tuned.predict(test_data)\n",
        "\n",
        "p = 0\n",
        "for i in range(len(test_labels)):\n",
        "  if p < 20:\n",
        "    if test_labels[i] != predicted[i]:\n",
        "      print(test_data['body'][i] + '\\n\\nTrue label: ' + test_labels[i] + ' Predicted label: ' + predicted[i] + '\\n')\n",
        "      p += 1\n",
        "  else:\n",
        "    break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Was watching a VOD from last years DreamHack Winter. The first map in the finals (Naama vs Mana) was Lost Temple.. spawning close ground positions..\n",
            "\n",
            "It's a great sign that shows how much the game is evolving imo. Has anyone else noticed stuff like this?\n",
            "\n",
            "True label: neutral Predicted label: positive\n",
            "\n",
            "I find it cool that both Mana and Naama made it to the Ro16 in this DH Winter. Shows that they weren't just flashes in the pan.\n",
            "\n",
            "True label: positive Predicted label: neutral\n",
            "\n",
            "Even better, watch a VOD from [MLG Raleigh](http://tv.majorleaguegaming.com/videos/174-wr4-g2-kiwikaki-vs-nadagast-steppes-of-war-mlg-raleigh-starcraft-2)\n",
            "\n",
            "The games, the casting, the maps... everything was fucking awful.  Amazing that it was just over one year ago.\n",
            "\n",
            "True label: neutral Predicted label: positive\n",
            "\n",
            "Your name and your post do not correlate \n",
            "\n",
            "True label: neutral Predicted label: very positive\n",
            "\n",
            "Deadpool just has scars because of the cancer doesn't he?\n",
            "Well stabbing him with kryptonite wouldn't be as effective since he'd heal straight away probably\n",
            "\n",
            "True label: neutral Predicted label: positive\n",
            "\n",
            "That happens a lot. Regular-Superman heals from Kryptonite stabbing/shooting/beatings beams pretty quickly after the rock is removed from his body. His healing factor is grossly underestimated on this subreddit.\n",
            "\n",
            "True label: positive Predicted label: neutral\n",
            "\n",
            "My favorite hero is Saitama (One-Punch Man) so... Not a lot more dangerous than he already is.\n",
            "\n",
            "True label: neutral Predicted label: very positive\n",
            "\n",
            "Healing factor as in wound healing (including dismemberment and the like) or complete regeneration of life?\n",
            "\n",
            "If its the latter, than Rai is almost unstoppable, if he can use his powers without worrying about draining his life\n",
            "\n",
            "If it's the former, then a good boost, but he was practically untouchable to begin with\n",
            "\n",
            "True label: positive Predicted label: neutral\n",
            "\n",
            "On a beach someplace warm and far away from anybody else. \n",
            "\n",
            "True label: positive Predicted label: neutral\n",
            "\n",
            "I don't do well running.  I am not enjoying myself the entire time.  On the other hand biking I quite enjoy.\n",
            "\n",
            "I think its just a matter of finding what works for you.  Instead of static weight lifting I also do kettlebell workouts because they feel more engaging to me.\n",
            "\n",
            "True label: positive Predicted label: neutral\n",
            "\n",
            "Sometimes its the type of exercise.  I hate being a group and running or competing.  But get in me in a personal challenge sport and I'm all for it.  I've taken up running as a challenge sport, trying to beat my mile times and going for longer and longer distances.  Swimming too, trying to swim for longer periods of time.\n",
            "\n",
            "BTW, I use to hate running and never understood how anyone could do it for fun.  Now I'm thinking about going for my first 5K in the spring.\n",
            "\n",
            "True label: negative Predicted label: neutral\n",
            "\n",
            "Thanks :)  I will go through some of my old book records and see if I can hit this for you.  Might also be worth your contacting the Bibliothèque nationale de France - one copy of all books published in France have to be deposited there by law, iirc.\n",
            "\n",
            "True label: positive Predicted label: neutral\n",
            "\n",
            "Beautiful music. This whole album is great.\n",
            "\n",
            "True label: positive Predicted label: very positive\n",
            "\n",
            "Saw this coming, still laughed.\n",
            "\n",
            "True label: positive Predicted label: neutral\n",
            "\n",
            "Ohhh my god dude, In my head I compiled a list of all the things that are wrong with the war on drugs and freedom country in general and then I was just amazed by the music....\n",
            "\n",
            "True label: negative Predicted label: neutral\n",
            "\n",
            "Incredible live and high \n",
            "\n",
            "True label: positive Predicted label: neutral\n",
            "\n",
            "Happiness\n",
            "\n",
            "True label: positive Predicted label: neutral\n",
            "\n",
            ":( that's too bad. I guess I'm lucky in that respect, my friends that I have now do things occasionally. But it's not the same as the people I grew up with and that feeling. I just miss those people in general. \n",
            "\n",
            "True label: neutral Predicted label: negative\n",
            "\n",
            "I recorded my voice http://www.speakpipe.com/voice-recorder/msg/o6p8pm8bwc21gnfq\n",
            "\n",
            "True label: neutral Predicted label: very positive\n",
            "\n",
            "Welcome to the wonderful world of Tame Impala. Fucking incredible band. My favorite.\n",
            "\n",
            "True label: positive Predicted label: very positive\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BRk206Vx84z"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oYICkmUygDS"
      },
      "source": [
        "# add title and majority_type to the model\n",
        "prediction_pipeline_union = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "          transformer_list=[\n",
        "            ('title', Pipeline([\n",
        "              ('selector', ItemSelector(key='title')),\n",
        "              ('one-hot', TfidfVectorizer(norm='l1')), \n",
        "              ])),\n",
        "            ('body', Pipeline([\n",
        "              ('selector', ItemSelector(key='body')), \n",
        "              ('one-hot', TfidfVectorizer(sublinear_tf=False, max_features=3000, max_df=1200)), \n",
        "              ])),\n",
        "            ('type', Pipeline([\n",
        "              ('selector', ItemSelector(key='majority_type')),\n",
        "              ('one-hot', TfidfVectorizer(norm='l1')), \n",
        "              ])),\n",
        "        ])\n",
        "        )\n",
        "    ])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O07oDgRG2NeA"
      },
      "source": [
        "train_features_union = prediction_pipeline_union.fit_transform(train_data)\n",
        "validation_features_union = prediction_pipeline_union.transform(validation_data)\n",
        "test_features_union = prediction_pipeline_union.transform(test_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWR7jmnU2u5q",
        "outputId": "81309f59-9dec-40c3-df6f-bda9432ed919"
      },
      "source": [
        "clf = LogisticRegression(solver='saga', max_iter = 1000, C=100)\n",
        "combined = clf.fit(train_features_union, train_labels)\n",
        "evaluation_summary(\"LR tf-idf\", combined.predict(test_features_union), test_labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR tf-idf\n",
            "Classifier 'LR tf-idf' has Acc=0.735 P=0.747 R=0.735 F1_w=0.740 F1_m=0.536\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.372     0.471     0.416       223\n",
            "      neutral      0.833     0.789     0.810      2654\n",
            "     positive      0.645     0.680     0.662      1045\n",
            "very negative      0.344     0.524     0.415        21\n",
            "very positive      0.349     0.411     0.377        73\n",
            "\n",
            "     accuracy                          0.735      4016\n",
            "    macro avg      0.509     0.575     0.536      4016\n",
            " weighted avg      0.747     0.735     0.740      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 105  162   11    3    1]\n",
            " [ 102 2094  287    7   24]\n",
            " [  10  363  711    0   18]\n",
            " [   6   14    1   11    0]\n",
            " [   0   21   35    0   30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sGABnOe9Fmx",
        "outputId": "48d4b85a-87b4-4318-b2cb-83ef0d8240a9"
      },
      "source": [
        "# add only title\n",
        "prediction_pipeline_union = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "          transformer_list=[\n",
        "            ('title', Pipeline([\n",
        "              ('selector', ItemSelector(key='title')),\n",
        "              ('one-hot', TfidfVectorizer(norm='l1')), \n",
        "              ])),\n",
        "            ('body', Pipeline([\n",
        "              ('selector', ItemSelector(key='body')), \n",
        "              ('one-hot', TfidfVectorizer(sublinear_tf=False, max_features=3000, max_df=1200)), \n",
        "              ])),\n",
        "        ])\n",
        "        )\n",
        "    ])\n",
        "\n",
        "train_features_union = prediction_pipeline_union.fit_transform(train_data)\n",
        "validation_features_union = prediction_pipeline_union.transform(validation_data)\n",
        "test_features_union = prediction_pipeline_union.transform(test_data)\n",
        "\n",
        "clf = LogisticRegression(solver='saga', max_iter = 1000, C=100)\n",
        "combined = clf.fit(train_features_union, train_labels)\n",
        "evaluation_summary(\"LR tf-idf\", combined.predict(test_features_union), test_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR tf-idf\n",
            "Classifier 'LR tf-idf' has Acc=0.736 P=0.750 R=0.736 F1_w=0.742 F1_m=0.523\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.348     0.456     0.394       215\n",
            "      neutral      0.835     0.788     0.811      2662\n",
            "     positive      0.652     0.679     0.665      1057\n",
            "very negative      0.250     0.444     0.320        18\n",
            "very positive      0.372     0.500     0.427        64\n",
            "\n",
            "     accuracy                          0.736      4016\n",
            "    macro avg      0.491     0.574     0.523      4016\n",
            " weighted avg      0.750     0.736     0.742      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  98  169   11    2    2]\n",
            " [  98 2098  292    8   18]\n",
            " [  12  360  718    0   12]\n",
            " [   7   15    2    8    0]\n",
            " [   0   20   34    0   32]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7mXBQntQ6Qa",
        "outputId": "46ad77b2-6076-4f48-bc5b-89eedfe0f78d"
      },
      "source": [
        "# add only author\n",
        "prediction_pipeline_union = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "          transformer_list=[\n",
        "            ('author', Pipeline([\n",
        "              ('selector', ItemSelector(key='author')),\n",
        "              ('one-hot', TfidfVectorizer(norm='l1')), \n",
        "              ])),\n",
        "            ('body', Pipeline([\n",
        "              ('selector', ItemSelector(key='body')), \n",
        "              ('one-hot', TfidfVectorizer(sublinear_tf=False, max_features=3000, max_df=1200)), \n",
        "              ])),\n",
        "        ])\n",
        "        )\n",
        "    ])\n",
        "\n",
        "train_features_union = prediction_pipeline_union.fit_transform(train_data)\n",
        "validation_features_union = prediction_pipeline_union.transform(validation_data)\n",
        "test_features_union = prediction_pipeline_union.transform(test_data)\n",
        "\n",
        "clf = LogisticRegression(solver='saga', max_iter = 1000, C=100)\n",
        "combined = clf.fit(train_features_union, train_labels)\n",
        "evaluation_summary(\"LR tf-idf\", combined.predict(test_features_union), test_labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR tf-idf\n",
            "Classifier 'LR tf-idf' has Acc=0.738 P=0.776 R=0.738 F1_w=0.752 F1_m=0.501\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.259     0.514     0.344       142\n",
            "      neutral      0.869     0.772     0.817      2832\n",
            "     positive      0.610     0.682     0.644       986\n",
            "very negative      0.219     0.538     0.311        13\n",
            "very positive      0.291     0.581     0.388        43\n",
            "\n",
            "     accuracy                          0.738      4016\n",
            "    macro avg      0.449     0.617     0.501      4016\n",
            " weighted avg      0.776     0.738     0.752      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  73  193   13    2    1]\n",
            " [  56 2185  262    4    7]\n",
            " [   6  414  672    0   10]\n",
            " [   7   16    2    7    0]\n",
            " [   0   24   37    0   25]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1aijschtISO",
        "outputId": "eacd5ebd-9956-443d-c462-bbd57dad269e"
      },
      "source": [
        "# add only majority_type\n",
        "prediction_pipeline_union = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "          transformer_list=[\n",
        "            ('type', Pipeline([\n",
        "              ('selector', ItemSelector(key='majority_type')),\n",
        "              ('one-hot', TfidfVectorizer(norm='l1')), \n",
        "              ])),\n",
        "            ('body', Pipeline([\n",
        "              ('selector', ItemSelector(key='body')), \n",
        "              ('one-hot', TfidfVectorizer(sublinear_tf=False, max_features=3000, max_df=1200)), \n",
        "              ])),\n",
        "        ])\n",
        "        )\n",
        "    ])\n",
        "\n",
        "train_features_union = prediction_pipeline_union.fit_transform(train_data)\n",
        "validation_features_union = prediction_pipeline_union.transform(validation_data)\n",
        "test_features_union = prediction_pipeline_union.transform(test_data)\n",
        "\n",
        "clf = LogisticRegression(solver='saga', max_iter = 1000, C=100)\n",
        "combined = clf.fit(train_features_union, train_labels)\n",
        "evaluation_summary(\"LR tf-idf\", combined.predict(test_features_union), test_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR tf-idf\n",
            "Classifier 'LR tf-idf' has Acc=0.750 P=0.757 R=0.750 F1_w=0.753 F1_m=0.530\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative      0.401     0.477     0.435       237\n",
            "      neutral      0.835     0.809     0.822      2596\n",
            "     positive      0.691     0.709     0.699      1074\n",
            "very negative      0.344     0.407     0.373        27\n",
            "very positive      0.314     0.329     0.321        82\n",
            "\n",
            "     accuracy                          0.750      4016\n",
            "    macro avg      0.517     0.546     0.530      4016\n",
            " weighted avg      0.757     0.750     0.753      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 113  154    8    5    2]\n",
            " [ 111 2099  266   11   27]\n",
            " [   6  309  761    0   26]\n",
            " [   6   14    1   11    0]\n",
            " [   1   20   38    0   27]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGQDQ_YExwed",
        "outputId": "e0fa75f7-f33b-42f4-ed8f-3e35f7661b66"
      },
      "source": [
        "# add only sentiment.subjectivity\n",
        "\n",
        "numeric_features = ['sentiment.subjectivity']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "text_features = ['body']\n",
        "text_transformer = TfidfVectorizer(sublinear_tf=False, max_features=3000, max_df=1200)\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('tfidf_1', text_transformer, 'body'),],\n",
        "                    remainder='drop')\n",
        "\n",
        "\n",
        "## Run evaluation with classifier\n",
        "def evaluateClassifier(classif):\n",
        "  clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('classifier', classif)])\n",
        "\n",
        "  clf.fit(train_data, train_labels)\n",
        "\n",
        "  y_pred = clf.predict(test_data)\n",
        "\n",
        "  print(metrics.classification_report(test_labels, y_pred, zero_division=0))\n",
        "\n",
        "evaluateClassifier(LogisticRegression(solver='saga', max_iter = 1000, C=100))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative       0.49      0.46      0.48       282\n",
            "      neutral       0.85      0.86      0.86      2514\n",
            "     positive       0.74      0.74      0.74      1102\n",
            "very negative       0.47      0.50      0.48        32\n",
            "very positive       0.46      0.38      0.42        86\n",
            "\n",
            "     accuracy                           0.79      4016\n",
            "    macro avg       0.60      0.59      0.60      4016\n",
            " weighted avg       0.78      0.79      0.79      4016\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg-UboVu1meW",
        "outputId": "4310eda9-7132-4f3a-e875-3ceb7a2c023a"
      },
      "source": [
        "# add sentiment.subjectivity and majority_type\n",
        "\n",
        "numeric_features = ['sentiment.subjectivity']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "text_features = ['body', 'majority_type']\n",
        "text_transformer = TfidfVectorizer(sublinear_tf=False, max_features=3000, max_df=1200)\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('tfidf_1', text_transformer, 'body'),\n",
        "        ('tfidf_2', text_transformer, 'majority_type')],\n",
        "                    remainder='drop')\n",
        "\n",
        "\n",
        "## Run evaluation with classifier\n",
        "def evaluateClassifier(classif):\n",
        "  clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('classifier', classif)])\n",
        "\n",
        "  clf.fit(train_data, train_labels)\n",
        "\n",
        "  y_pred = clf.predict(test_data)\n",
        "\n",
        "  print(metrics.classification_report(test_labels, y_pred, zero_division=0))\n",
        "\n",
        "evaluateClassifier(LogisticRegression(solver='saga', max_iter = 1000, C=100))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negative       0.50      0.47      0.49       282\n",
            "      neutral       0.85      0.86      0.86      2514\n",
            "     positive       0.74      0.73      0.74      1102\n",
            "very negative       0.55      0.50      0.52        32\n",
            "very positive       0.42      0.38      0.40        86\n",
            "\n",
            "     accuracy                           0.79      4016\n",
            "    macro avg       0.61      0.59      0.60      4016\n",
            " weighted avg       0.78      0.79      0.79      4016\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCph-pl-2c6V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}